{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SetUpAndTearDown(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        print('Setup')\n",
    "\n",
    "    def tearDown(self):\n",
    "        print('TearDown')\n",
    "\n",
    "    def test_pass(self):\n",
    "        print('Passing test')\n",
    "\n",
    "    def test_error(self):\n",
    "        print('Test resulting in an error')\n",
    "        raise ValueError()\n",
    "\n",
    "    def test_fail(self):\n",
    "        print('Failing test')\n",
    "        self.fail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EF."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup\n",
      "Test resulting in an error\n",
      "TearDown\n",
      "Setup\n",
      "Failing test\n",
      "TearDown\n",
      "Setup\n",
      "Passing test\n",
      "TearDown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ERROR: test_error (__main__.SetUpAndTearDown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-9f86f77f8664>\", line 13, in test_error\n",
      "    raise ValueError()\n",
      "ValueError\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_fail (__main__.SetUpAndTearDown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-9f86f77f8664>\", line 17, in test_fail\n",
      "    self.fail()\n",
      "AssertionError: None\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.008s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fd9a44f1550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['python', 'SetUpAndTearDown'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InvalidSetUp(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.stream = open('README.md', 'r')\n",
    "        print('SetUp')\n",
    "        raise Exception()\n",
    "\n",
    "    def tearDown(self):\n",
    "        self.stream.close()\n",
    "        print('TearDown')\n",
    "\n",
    "    def test_one(self):\n",
    "        print('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SetUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ERROR: test_one (__main__.InvalidSetUp)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-7712b10ca369>\", line 5, in setUp\n",
      "    raise Exception()\n",
      "Exception\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fd9a8b41d68>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['python', 'InvalidSetUp'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BetterSetUp(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.stream = open('README.md', 'r')\n",
    "        self.addCleanup(lambda: print('Stream closed'))\n",
    "        self.addCleanup(self.stream.close)\n",
    "        self.addCleanup(lambda: print('Closing stream'))\n",
    "        print('SetUp')\n",
    "        raise Exception()\n",
    "\n",
    "    def test_one(self):\n",
    "        print('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SetUp\n",
      "Closing stream\n",
      "Stream closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ERROR: test_one (__main__.BetterSetUp)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-8-f6f98e31bdaa>\", line 8, in setUp\n",
      "    raise Exception()\n",
      "Exception\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.007s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fd9a45111d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['python', 'BetterSetUp'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SetUpClassAndTearDownClass(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        print('SetupClass')\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        print('TearDownClass')\n",
    "        \n",
    "    def setUp(self):\n",
    "        print('Setup')\n",
    "\n",
    "    def tearDown(self):\n",
    "        print('TearDown')\n",
    "\n",
    "    def test_pass(self):\n",
    "        print('Passing test')\n",
    "\n",
    "    def test_error(self):\n",
    "        print('Test resulting in an error')\n",
    "        raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SetupClass\n",
      "Setup\n",
      "Test resulting in an error\n",
      "TearDown\n",
      "Setup\n",
      "Passing test\n",
      "TearDown\n",
      "TearDownClass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ERROR: test_error (__main__.SetUpClassAndTearDownClass)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-14-ba24c2099e25>\", line 21, in test_error\n",
      "    raise ValueError()\n",
      "ValueError\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.008s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fd9a44a17f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['python', 'SetUpClassAndTearDownClass'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "class Skipping(unittest.TestCase):\n",
    "    @unittest.skip('demonstrating skipping')\n",
    "    def test_noting(self):\n",
    "        self.fail('should not be executed')\n",
    "\n",
    "    @unittest.skipUnless(sys.platform.startswith('win'),\n",
    "                         'requires Windows')\n",
    "    def test_windows_support(self):\n",
    "        pass\n",
    "\n",
    "    @unittest.skipIf(sys.version.startswith('3'),\n",
    "                     'requires Python 2')\n",
    "    def test_python_2_support(self):\n",
    "        pass\n",
    "\n",
    "    @unittest.expectedFailure\n",
    "    def test_expected_failure(self):\n",
    "        self.fail('should be executed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xsss\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.009s\n",
      "\n",
      "OK (skipped=3, expected failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fd9a44a86a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['python', 'Skipping'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubTests(unittest.TestCase):\n",
    "    def test_subtest(self):\n",
    "        for a, b, expected in [\n",
    "            (0, 0, 0),\n",
    "            (2, 2, 4),\n",
    "            (2, 5, 5),\n",
    "            (2, 7, 7),\n",
    "        ]:\n",
    "            with self.subTest(a=a, b=b, expected=expected):\n",
    "                print('Subtest')\n",
    "                got = a + b\n",
    "                self.assertEqual(got, expected)\n",
    "\n",
    "    def setUp(self):\n",
    "        print('SetUp')\n",
    "\n",
    "    def tearDown(self):\n",
    "        print('TearDown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SetUp\n",
      "Subtest\n",
      "Subtest\n",
      "Subtest\n",
      "Subtest\n",
      "TearDown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FAIL: test_subtest (__main__.SubTests) (a=2, b=5, expected=5)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-26-090ef11344cb>\", line 12, in test_subtest\n",
      "    self.assertEqual(got, expected)\n",
      "AssertionError: 7 != 5\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_subtest (__main__.SubTests) (a=2, b=7, expected=7)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-26-090ef11344cb>\", line 12, in test_subtest\n",
      "    self.assertEqual(got, expected)\n",
      "AssertionError: 9 != 7\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fd9a44b2c50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['python', 'SubTests'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_module.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_module.py\n",
    "import os\n",
    "\n",
    "\n",
    "DEFAULT_EXTENSION = '.txt'\n",
    "\n",
    "\n",
    "def my_remove(filename):\n",
    "    if '.' not in filename:\n",
    "        filename += DEFAULT_EXTENSION\n",
    "    os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_my_module.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_my_module.py\n",
    "import unittest\n",
    "from unittest import mock\n",
    "from my_module import my_remove\n",
    "\n",
    "class PatchingTestCase(unittest.TestCase):\n",
    "    @mock.patch('my_module.os')\n",
    "    def test_provided_extension_should_be_used(self, os_mock):\n",
    "        my_remove('file.md')\n",
    "        os_mock.remove.assert_called_once_with('file.md')\n",
    "\n",
    "    @mock.patch('my_module.os')\n",
    "    def test_when_extension_is_missing_then_use_default_one(self, os_mock):\n",
    "        my_remove('file')\n",
    "        os_mock.remove.assert_called_once_with('file.txt')\n",
    "        \n",
    "    @mock.patch('my_module.os')\n",
    "    def test_hidden_files(self, os_mock):\n",
    "        my_remove('.file')\n",
    "        os_mock.remove.assert_called_once_with('.file.txt')\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F..\r\n",
      "======================================================================\r\n",
      "FAIL: test_hidden_files (__main__.PatchingTestCase)\r\n",
      "----------------------------------------------------------------------\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/lib/python3.5/unittest/mock.py\", line 1159, in patched\r\n",
      "    return func(*args, **keywargs)\r\n",
      "  File \"test_my_module.py\", line 19, in test_hidden_files\r\n",
      "    os_mock.remove.assert_called_once_with('.file.txt')\r\n",
      "  File \"/usr/lib/python3.5/unittest/mock.py\", line 805, in assert_called_once_with\r\n",
      "    return self.assert_called_with(*args, **kwargs)\r\n",
      "  File \"/usr/lib/python3.5/unittest/mock.py\", line 794, in assert_called_with\r\n",
      "    raise AssertionError(_error_message()) from cause\r\n",
      "AssertionError: Expected call: remove('.file.txt')\r\n",
      "Actual call: remove('.file')\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.006s\r\n",
      "\r\n",
      "FAILED (failures=1)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 test_my_module.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
